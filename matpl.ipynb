{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5793f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.1-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "     ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     ---------------------------------------- 0.1/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.2/7.6 MB 1.5 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.3/7.6 MB 1.5 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.4/7.6 MB 2.0 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 0.6/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.9/7.6 MB 2.7 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.1/7.6 MB 3.0 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 1.2/7.6 MB 3.0 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 1.5/7.6 MB 3.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 1.6/7.6 MB 3.3 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 1.8/7.6 MB 3.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 2.0/7.6 MB 3.3 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 2.1/7.6 MB 3.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 2.3/7.6 MB 3.4 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 2.5/7.6 MB 3.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 2.7/7.6 MB 3.5 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 3.0/7.6 MB 3.6 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 3.1/7.6 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 3.3/7.6 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 3.5/7.6 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 3.7/7.6 MB 3.7 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 3.9/7.6 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 4.0/7.6 MB 3.6 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 4.2/7.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 4.3/7.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 4.5/7.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 4.7/7.6 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 4.9/7.6 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 5.1/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 5.3/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 5.5/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 5.6/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 5.8/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 6.0/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 6.3/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 6.4/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 6.6/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 6.8/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 7.0/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 7.2/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 7.4/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.6/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.6/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.6/7.6 MB 3.6 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hp\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.5.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.2/2.5 MB 3.5 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.3/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 0.4/2.5 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.6/2.5 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.8/2.5 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 1.1/2.5 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.3/2.5 MB 4.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.4/2.5 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.6/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.8/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 2.0/2.5 MB 4.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.1/2.5 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.3/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-win_amd64.whl (160 kB)\n",
      "     ---------------------------------------- 0.0/160.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 160.2/160.2 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.3 importlib-resources-5.12.0 kiwisolver-1.4.4 matplotlib-3.7.1 pillow-9.5.0 pyparsing-3.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc68170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b88e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbe889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 143 images belonging to 10 classes.\n",
      "Found 52 images belonging to 10 classes.\n",
      "{'Tomato - Bacterial_spot': 0, 'Tomato - Early_blight': 1, 'Tomato - Healthy': 2, 'Tomato - Late_blight': 3, 'Tomato - Leaf_Mold': 4, 'Tomato - Septoria_leaf_spot': 5, 'Tomato - Target_Spot': 6, 'Tomato - Tomato_Yellow_Leaf_Curl_Virus': 7, 'Tomato - Tomato_mosaic_virus': 8, 'Tomato - Two-spotted_spider_mite': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13380\\2711295950.py:41: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "#basic cnn\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/hp/OneDrive/Desktop/plant/Plant-Leaf-Disease-Prediction-main/Dataset/train', # relative path from working directoy\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 6, class_mode = 'categorical')\n",
    "valid_set = test_datagen.flow_from_directory('C:/Users/hp/OneDrive/Desktop/plant/Plant-Leaf-Disease-Prediction-main/Dataset/val', # relative path from working directoy\n",
    "                                             target_size = (128, 128), \n",
    "                                        batch_size = 3, class_mode = 'categorical')\n",
    "\n",
    "labels = (training_set.class_indices)\n",
    "print(labels)\n",
    "\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 20,\n",
    "                         epochs = 50,\n",
    "                         validation_data=valid_set\n",
    "\n",
    "                         )\n",
    "\n",
    "classifier_json=classifier.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "# serialize weights to HDF5\n",
    "    classifier.save_weights(\"my_model_weights.h5\")\n",
    "    classifier.save(\"model.h66\")\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6759f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dcb92e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1537116207.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    CV2 reads an image in BGR format. We need to convert it to RGB\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\hp\\OneDrive\\Desktop\\plant\\Plant-Leaf-Disease-Prediction-main\\Dataset\\train\\Tomato - Bacterial_spot\\Tomato___Bacterial_spot (3).jpg\")\n",
    "img_resize = cv2.resize(img, (128,128))\n",
    "\n",
    "\n",
    "CV2 reads an image in BGR format. We need to convert it to RGB\n",
    "b,g,r = cv2.split(img_resize)       # get b,g,r\n",
    "rgb_img = cv2.merge([r,g,b])     # switch it to rgb\n",
    "\n",
    "\n",
    "plt.imshow(rgb_img)\n",
    "label_map = (training_set.class_indices)\n",
    "\n",
    "print(label_map)\n",
    "img_rank4 = np.expand_dims(rgb_img/255, axis=0)\n",
    "\n",
    "classifier.predict(img_rank4)\n",
    "h = list(label_map.keys())[classifier.predict_classes(img_rank4)[0]]\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "cv2.putText(img, h, (10, 30), font, 1.0, (0, 0, 255), 1)\n",
    "cv2.imshow(h,img)\n",
    "\n",
    "print(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "#basic cnn\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/hp/OneDrive/Desktop/plant/Plant-Leaf-Disease-Prediction-main/Dataset/train', # relative path from working directoy\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 6, class_mode = 'categorical')\n",
    "valid_set = test_datagen.flow_from_directory('C:/Users/hp/OneDrive/Desktop/plant/Plant-Leaf-Disease-Prediction-main/Dataset/val', # relative path from working directoy\n",
    "                                             target_size = (128, 128), \n",
    "                                        batch_size = 3, class_mode = 'categorical')\n",
    "\n",
    "labels = (training_set.class_indices)\n",
    "print(labels)\n",
    "\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 20,\n",
    "                         epochs = 50,\n",
    "                         validation_data=valid_set\n",
    "\n",
    "                         )\n",
    "\n",
    "classifier_json=classifier.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "# serialize weights to HDF5\n",
    "    classifier.save_weights(\"my_model_weights.h5\")\n",
    "    classifier.save(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('C:/Users/Madhuri/AppData/Local/Program.jpg')\n",
    "img_resize = cv2.resize(img, (128,128))\n",
    "\n",
    "\n",
    "#CV2 reads an image in BGR format. We need to convert it to RGB\n",
    "b,g,r = cv2.split(img_resize)       # get b,g,r\n",
    "rgb_img = cv2.merge([r,g,b])     # switch it to rgb\n",
    "\n",
    "\n",
    "plt.imshow(rgb_img)\n",
    "label_map = (training_set.class_indices)\n",
    "\n",
    "print(label_map)\n",
    "img_rank4 = np.expand_dims(rgb_img/255, axis=0)\n",
    "\n",
    "classifier.predict(img_rank4)\n",
    "h = list(label_map.keys())[classifier.predict_classes(img_rank4)[0]]\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "cv2.putText(img, h, (10, 30), font, 1.0, (0, 0, 255), 1)\n",
    "cv2.imshow(h,img)\n",
    "\n",
    "print(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db630dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505728f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "print ('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9d9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
